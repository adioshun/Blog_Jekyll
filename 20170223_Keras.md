# 개요

케라스는 널리 사용되고 있는 티아노(Theano)와 요즘 많이 쓰고 있는 텐서플로우(TensorFlow)를 위한 딥러닝 라이브러리입니다. 케라스는 아이디어를 빨리 구현하고 실험하기 위한 목적에 포커스가 맞춰진 만큼 굉장히 간결하고 쉽게 사용할 수 있도록 파이썬으로 구현된 상위 레벨의 라이브러리입니다. 즉 내부적으론 티아노와 텐서플로우가 구동되지만 연구자는 복잡한 티아노와 텐서플로우를 알 필요는 없습니다. 케라스는 쉽게 컨볼루션 신경망, 순환 신경망 또는 이를 조합한 신경망은 물론 다중 입력 또는 다중 출력 등 다양한 연결 구성을 할 수 있습니다.

# 설치
1. Dependency 설치
```
sudo apt-get install libhdf5-dev
pip install pyyaml h5py
```
2. 패키지 설치
```
pip install keras
```
Keras 백엔드로 Tensorflow 설정
```
$ mkdir -p ~/.keras
$ echo '{"epsilon":1e-07,"floatx":"float32","backend":"tensorflow"}' > ~/.keras/keras.json
```

# Python에서 Keara 사용
from keras import backend as K

## 1. Regular Dense, MLP type
```
keras.layers.core.Dense(
                output_dim, 
                init='glorot_uniform', 
                activation=None, 
                weights=None, 
                W_regularizer=None, 
                b_regularizer=None, 
                activity_regularizer=None, 
                W_constraint=None, 
                b_constraint=None, 
                bias=True, 
                input_dim=None
)
```
* [파라미터 설명](https://keras.io/layers/core/#dense)

## 2. Recurrent layers, LSTM, GRU, etc. 
```
keras.layers.recurrent.Recurrent(
                weights=None, 
                return_sequences=False, 
                go_backwards=False, 
                stateful=False, 
                unroll=False, 
                consume_less='cpu', 
                input_dim=None, 
                input_length=None
)
```
* [파라미터 설명](https://keras.io/layers/recurrent/)
* LSTM, GRU and SimpleRNN 등 사용 가능


## 3. 1D Convolution layers
```
keras.layers.convolutional.Convolution1D(
                nb_filter, 
                filter_length, 
                init='glorot_uniform', 
                activation=None, 
                weights=None, 
                border_mode='valid', 
                subsample_length=1, 
                W_regularizer=None, 
                b_regularizer=None, 
                activity_regularizer=None, 
                W_constraint=None, 
                b_constraint=None, 
                bias=True, 
                input_dim=None, 
                input_length=None
)
```

* [파라미터 설명](https://keras.io/layers/convolutional/)



## 4. 2D Convolution layers
keras.layers.convolutional.Convolution2D(
                nb_filter, 
                nb_row, nb_col, 
                init='glorot_uniform', 
                activation=None, 
                weights=None, 
                border_mode='valid', 
                subsample=(1, 1), 
                dim_ordering='default', 
                W_regularizer=None, 
                b_regularizer=None, 
                activity_regularizer=None, 
                W_constraint=None, 
                b_constraint=None, 
                bias=True
)

* [파라미터 설명](https://keras.io/layers/convolutional/#convolution2d)




## 5. Autoencoder
Autoencoders can be built with any other type of layer
```
from keras.layers import containers

#imput shape: (nb_samples.32)
encoder = containers.Sequential([Dense(16, input_dim=32), Dense(8)])
decoder = containers.Sequential([Dense(16, input_dim=8), Dense(32)])

autoencoder = Sequential()
autoencoder.add(AutoEncoder(encoder=encoder, decoder=decoder, output_reconstruction=False))
```

## Other types of layers include
* Dropout
* Noise
* Pooling
* Normalization
* Embedding
* and so on....


## Activations
* Sigmoid, tanh, ReLu, softplus, hard_sigmoid, linear
* Advanced activations : LeakyRelu, PReLu, ELU, Parametric Softplus, Thresholded linear, Thresholded ReLu


## ObJective Fucntion
* Error Loss : RMSE, MSE, MAE, MAPE, MSLE
* Hinge Loss : Squared_hinge, Hinge
* Class Loss : Binary\_crossentropy, categorical\_crossentropy

## Optimization 
* SGD, AdaGrad, AdaDelta, Rmsprop, Adam
* Alll optimizer can be customized via parameters


































































